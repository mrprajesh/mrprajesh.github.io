<!DOCTYPE html><html lang="en" > <script src="https://cdn.jsdelivr.net/npm/anchor-js/anchor.min.js"></script><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Understanding CUDA packages installed using pip – errors &amp; fix" /><meta name="author" content="Rajesh Pandian M" /><meta property="og:locale" content="en_US" /><meta name="description" content="After we install newer CUDA toolkit some python code written using numpy+cupy+numba showed the below error on running. Yes, even after setting the newer cuda home export CUDA_HOME=/usr/local/cuda-11.5." /><meta property="og:description" content="After we install newer CUDA toolkit some python code written using numpy+cupy+numba showed the below error on running. Yes, even after setting the newer cuda home export CUDA_HOME=/usr/local/cuda-11.5." /><link rel="canonical" href="https://mrprajesh.co.in/blog/understand-cuda-packages-using-pip.html" /><meta property="og:url" content="https://mrprajesh.co.in/blog/understand-cuda-packages-using-pip.html" /><meta property="og:site_name" content="Rajesh’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-12-28T14:25:34+05:30" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Understanding CUDA packages installed using pip – errors &amp; fix" /><meta name="twitter:site" content="@mrprajesh" /><meta name="twitter:creator" content="@Rajesh Pandian M" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Rajesh Pandian M"},"dateModified":"2022-12-28T14:25:34+05:30","datePublished":"2022-12-28T14:25:34+05:30","description":"After we install newer CUDA toolkit some python code written using numpy+cupy+numba showed the below error on running. Yes, even after setting the newer cuda home export CUDA_HOME=/usr/local/cuda-11.5.","headline":"Understanding CUDA packages installed using pip – errors &amp; fix","mainEntityOfPage":{"@type":"WebPage","@id":"https://mrprajesh.co.in/blog/understand-cuda-packages-using-pip.html"},"url":"https://mrprajesh.co.in/blog/understand-cuda-packages-using-pip.html"}</script><title> Understanding CUDA packages installed using pip -- errors &amp; fix - Rajesh&#39;s Blog</title><link rel="shortcut icon" href="/blog/favicon.png"><link rel="alternate" type="application/atom+xml" title="Rajesh's Blog" href="/blog/atom.xml"><link rel="alternate" type="application/json" title="Rajesh's Blog" href="https://mrprajesh.co.in/blog/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/blog/sitemap.xml" /><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui, sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code{padding:.1rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:0.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:0.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}#footer{padding-bottom:2em;text-align:center;clear:both;width:80%;margin:20px auto} .anchorjs-link { color: #aaa; } .anchorjs-link:hover { color: #ff5231; }</style></head><body><main role="main"><header role="banner"> <!--<h1 class="logo">Rajesh's Blog</h1>--><nav role="navigation"><ul><li><a href="/blog/" >My Blog</a></li><li><a href="/blog/about" >About</a></li><li><a href="/blog/search" >Search</a></li><li><a href="/blog/tags" >Tags</a></li><li><a href="/blog/atom.xml" >RSS</a></li></ul></nav></header><section class="post"><link rel="stylesheet" type="text/css" href="/blog/monokai.css"><h2>Understanding CUDA packages installed using pip -- errors & fix</h2><p>After we install newer CUDA toolkit some python code written using numpy+cupy+numba showed the below error on running. Yes, even after setting the newer cuda home <code class="language-plaintext highlighter-rouge">export CUDA_HOME=/usr/local/cuda-11.5</code>.</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span><span class="o">:</span>
  <span class="n">File</span> <span class="s">"ga-vrp-gpu.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">684</span><span class="p">,</span> <span class="n">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
    <span class="n">calc_cost_gpu</span><span class="p">[</span><span class="n">blocks</span><span class="p">,</span> <span class="n">threads_per_block</span><span class="p">](</span><span class="n">data_d</span><span class="p">,</span> <span class="n">popsize</span><span class="p">,</span> <span class="n">vrp_capacity</span><span class="p">,</span> <span class="n">cost_table_d</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">804</span><span class="p">,</span> <span class="n">in</span> <span class="n">__call__</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">specialize</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">815</span><span class="p">,</span> <span class="n">in</span> <span class="n">specialize</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">argtypes</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">834</span><span class="p">,</span> <span class="n">in</span> <span class="n">compile</span>
    <span class="n">kernel</span><span class="p">.</span><span class="n">bind</span><span class="p">()</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">548</span><span class="p">,</span> <span class="n">in</span> <span class="n">bind</span>
    <span class="n">self</span><span class="p">.</span><span class="n">_func</span><span class="p">.</span><span class="n">get</span><span class="p">()</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">426</span><span class="p">,</span> <span class="n">in</span> <span class="n">get</span>
    <span class="n">ptx</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">ptx</span><span class="p">.</span><span class="n">get</span><span class="p">()</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/compiler.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">397</span><span class="p">,</span> <span class="n">in</span> <span class="n">get</span>
    <span class="o">**</span><span class="n">self</span><span class="p">.</span><span class="n">_extra_options</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/cudadrv/nvvm.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">496</span><span class="p">,</span> <span class="n">in</span> <span class="n">llvm_to_ptx</span>
    <span class="n">ptx</span> <span class="o">=</span> <span class="n">cu</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="o">**</span><span class="n">opts</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/cudadrv/nvvm.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">233</span><span class="p">,</span> <span class="n">in</span> <span class="n">compile</span>
    <span class="n">self</span><span class="p">.</span><span class="n">_try_error</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="err">'</span><span class="n">Failed</span> <span class="n">to</span> <span class="n">compile</span><span class="err">\</span><span class="n">n</span><span class="err">'</span><span class="p">)</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/cudadrv/nvvm.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">251</span><span class="p">,</span> <span class="n">in</span> <span class="n">_try_error</span>
    <span class="n">self</span><span class="p">.</span><span class="n">driver</span><span class="p">.</span><span class="n">check_error</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="s">"%s</span><span class="se">\n</span><span class="s">%s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">get_log</span><span class="p">()))</span>
  <span class="n">File</span> <span class="s">"/home/rajesh/.local/lib/python3.6/site-packages/numba/cuda/cudadrv/nvvm.py"</span><span class="p">,</span> <span class="n">line</span> <span class="mi">141</span><span class="p">,</span> <span class="n">in</span> <span class="n">check_error</span>
    <span class="n">raise</span> <span class="n">exc</span>
<span class="n">numba</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">cudadrv</span><span class="p">.</span><span class="n">error</span><span class="p">.</span><span class="n">NvvmError</span><span class="o">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">compile</span>

<span class="o">&lt;</span><span class="n">unnamed</span><span class="o">&gt;</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span><span class="o">:</span> <span class="n">parse</span> <span class="n">expected</span> <span class="n">comma</span> <span class="n">after</span> <span class="n">load</span><span class="err">'</span><span class="n">s</span> <span class="n">type</span>
<span class="n">NVVM_ERROR_COMPILATION</span>

</code></pre></div></div><h3 id="steps-to-resolve">Steps to Resolve.</h3><ol><li>Uninstall dependencies <code class="language-plaintext highlighter-rouge">pip3 uninstall cupy numba numpy</code></li><li>Set newer environment <code class="language-plaintext highlighter-rouge">export CUDA_HOME=/usr/local/cuda-11.5</code></li><li>Install again. <code class="language-plaintext highlighter-rouge">pip3 install cupy numba numpy</code></li><li>Make sure to export <code class="language-plaintext highlighter-rouge">CUDA_HOME</code> or in <code class="language-plaintext highlighter-rouge">.bashrc</code> before running <code class="language-plaintext highlighter-rouge">python3 gpu-program.py</code></li></ol><h2 id="office-use">Office use</h2><h3 id="collect-env-details">Collect env details</h3><p>Took this from pytorch git repo.</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp"># For security purposes, please check the contents of collect_env.py before running it.
</span>
<span class="n">wget</span> <span class="n">https</span><span class="o">:</span><span class="c1">//raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py </span>
<span class="n">python3</span> <span class="n">collect_env</span><span class="p">.</span><span class="n">py</span>
</code></pre></div></div><h3 id="my-env-details">My env details.</h3><p>On my local machine.</p><div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Collecting</span> <span class="n">environment</span> <span class="n">information</span><span class="p">...</span>
<span class="n">PyTorch</span> <span class="n">version</span><span class="o">:</span> <span class="mi">1</span><span class="p">.</span><span class="mi">13</span><span class="p">.</span><span class="mi">0</span><span class="o">+</span><span class="n">cu117</span>
<span class="n">Is</span> <span class="n">debug</span> <span class="n">build</span><span class="o">:</span> <span class="n">False</span>
<span class="n">CUDA</span> <span class="n">used</span> <span class="n">to</span> <span class="n">build</span> <span class="n">PyTorch</span><span class="o">:</span> <span class="mi">11</span><span class="p">.</span><span class="mi">7</span>
<span class="n">ROCM</span> <span class="n">used</span> <span class="n">to</span> <span class="n">build</span> <span class="n">PyTorch</span><span class="o">:</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>

<span class="n">OS</span><span class="o">:</span> <span class="n">Linux</span> <span class="n">Mint</span> <span class="mi">20</span><span class="p">.</span><span class="mi">3</span> <span class="p">(</span><span class="n">x86_64</span><span class="p">)</span>
<span class="n">GCC</span> <span class="n">version</span><span class="o">:</span> <span class="p">(</span><span class="n">Ubuntu</span> <span class="mi">9</span><span class="p">.</span><span class="mi">4</span><span class="p">.</span><span class="mi">0</span><span class="o">-</span><span class="mi">1u</span><span class="n">buntu1</span><span class="o">~</span><span class="mi">20</span><span class="p">.</span><span class="mo">04</span><span class="p">.</span><span class="mi">1</span><span class="p">)</span> <span class="mi">9</span><span class="p">.</span><span class="mi">4</span><span class="p">.</span><span class="mi">0</span>
<span class="n">Clang</span> <span class="n">version</span><span class="o">:</span> <span class="n">Could</span> <span class="n">not</span> <span class="n">collect</span>
<span class="n">CMake</span> <span class="n">version</span><span class="o">:</span> <span class="n">version</span> <span class="mi">3</span><span class="p">.</span><span class="mi">16</span><span class="p">.</span><span class="mi">3</span>
<span class="n">Libc</span> <span class="n">version</span><span class="o">:</span> <span class="n">glibc</span><span class="o">-</span><span class="mi">2</span><span class="p">.</span><span class="mi">31</span>

<span class="n">Python</span> <span class="n">version</span><span class="o">:</span> <span class="mi">3</span><span class="p">.</span><span class="mi">8</span><span class="p">.</span><span class="mi">10</span> <span class="p">(</span><span class="k">default</span><span class="p">,</span> <span class="n">Jun</span> <span class="mi">22</span> <span class="mi">2022</span><span class="p">,</span> <span class="mi">20</span><span class="o">:</span><span class="mi">18</span><span class="o">:</span><span class="mi">18</span><span class="p">)</span>  <span class="p">[</span><span class="n">GCC</span> <span class="mi">9</span><span class="p">.</span><span class="mi">4</span><span class="p">.</span><span class="mi">0</span><span class="p">]</span> <span class="p">(</span><span class="mi">64</span><span class="o">-</span><span class="n">bit</span> <span class="n">runtime</span><span class="p">)</span>
<span class="n">Python</span> <span class="n">platform</span><span class="o">:</span> <span class="n">Linux</span><span class="o">-</span><span class="mi">5</span><span class="p">.</span><span class="mi">15</span><span class="p">.</span><span class="mi">0</span><span class="o">-</span><span class="mi">41</span><span class="o">-</span><span class="n">generic</span><span class="o">-</span><span class="n">x86_64</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">glibc2</span><span class="p">.</span><span class="mi">29</span>
<span class="n">Is</span> <span class="n">CUDA</span> <span class="n">available</span><span class="o">:</span> <span class="n">True</span>
<span class="n">CUDA</span> <span class="n">runtime</span> <span class="n">version</span><span class="o">:</span> <span class="mi">11</span><span class="p">.</span><span class="mi">7</span><span class="p">.</span><span class="mi">64</span>
<span class="n">CUDA_MODULE_LOADING</span> <span class="n">set</span> <span class="n">to</span><span class="o">:</span> <span class="n">LAZY</span>
<span class="n">GPU</span> <span class="n">models</span> <span class="n">and</span> <span class="n">configuration</span><span class="o">:</span> <span class="n">GPU</span> <span class="mi">0</span><span class="o">:</span> <span class="n">NVIDIA</span> <span class="n">GeForce</span> <span class="n">RTX</span> <span class="mi">3060</span> <span class="n">Laptop</span> <span class="n">GPU</span>
<span class="n">Nvidia</span> <span class="n">driver</span> <span class="n">version</span><span class="o">:</span> <span class="mi">515</span><span class="p">.</span><span class="mi">48</span><span class="p">.</span><span class="mo">07</span>
<span class="n">cuDNN</span> <span class="n">version</span><span class="o">:</span> <span class="n">Could</span> <span class="n">not</span> <span class="n">collect</span>
<span class="n">HIP</span> <span class="n">runtime</span> <span class="n">version</span><span class="o">:</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>
<span class="n">MIOpen</span> <span class="n">runtime</span> <span class="n">version</span><span class="o">:</span> <span class="n">N</span><span class="o">/</span><span class="n">A</span>
<span class="n">Is</span> <span class="n">XNNPACK</span> <span class="n">available</span><span class="o">:</span> <span class="n">True</span>

<span class="n">Versions</span> <span class="n">of</span> <span class="n">relevant</span> <span class="n">libraries</span><span class="o">:</span>
<span class="p">[</span><span class="n">pip3</span><span class="p">]</span> <span class="n">numpy</span><span class="o">==</span><span class="mi">1</span><span class="p">.</span><span class="mi">23</span><span class="p">.</span><span class="mi">5</span>
<span class="p">[</span><span class="n">pip3</span><span class="p">]</span> <span class="n">torch</span><span class="o">==</span><span class="mi">1</span><span class="p">.</span><span class="mi">13</span><span class="p">.</span><span class="mi">0</span>
<span class="p">[</span><span class="n">pip3</span><span class="p">]</span> <span class="n">torchaudio</span><span class="o">==</span><span class="mi">0</span><span class="p">.</span><span class="mi">13</span><span class="p">.</span><span class="mi">0</span>
<span class="p">[</span><span class="n">pip3</span><span class="p">]</span> <span class="n">torchvision</span><span class="o">==</span><span class="mi">0</span><span class="p">.</span><span class="mi">14</span><span class="p">.</span><span class="mi">0</span>
<span class="p">[</span><span class="n">conda</span><span class="p">]</span> <span class="n">No</span> <span class="n">relevant</span> <span class="n">packages</span>
</code></pre></div></div><span class="meta"> ★ 5 min read &middot; <a href="/" > Rajesh Pandian M</a> &middot; <time datetime="2022-12-28T14:25:34+05:30">28-Dec-2022 14:25:34 (IST)</time> <!-- date: "%d-%b-%Y %T %Z (UTC%z)" --> ★ <a href="/blog/tag/python"> python </a> , <a href="/blog/tag/cuda"> cuda </a> , <a href="/blog/tag/pip"> pip </a> , <a href="/blog/tag/cupy"> cupy </a> , <a href="/blog/tag/numba"> numba </a> , <a href="/blog/tag/numpy"> numpy </a> </span> <script src="https://utteranc.es/client.js" repo="mrprajesh/blog" issue-term="pathname" label="comments" theme="github-light" crossorigin="anonymous" async> </script> <!--<span class="meta"><time datetime="2022-12-28T14:25:34+05:30">December 28, 2022</time> &middot; <a class="post" href="/tag/python">python</a>, <a class="post" href="/tag/cuda">cuda</a>, <a class="post" href="/tag/pip">pip</a>, <a class="post" href="/tag/cupy">cupy</a>, <a class="post" href="/tag/numba">numba</a>, <a class="post" href="/tag/numpy">numpy</a></span> --></section></main><footer id="footer" class="body"><p> Made with ❤ <a href="https://jekyllrb.com//">Jekyll</a> &nbsp;&nbsp; &nbsp; | &nbsp; Customized <a href="https://github.com/ronv/sidey"> «Sidey» </a> theme &nbsp; | &nbsp; Fork/Star <a href="https://github.com/mrprajesh/blog">on GitHub </a></p><p id="LDate">Last Modified On: Friday, 16 February 2024 08:00:33 IST</p></footer><script> anchors.options.placement = 'left'; anchors.add(); </script></body></html>
